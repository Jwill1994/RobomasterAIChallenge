{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=Green>사용하는 함수</font>\n",
    "\n",
    "\n",
    "###  <font color=blue>1.SetBehaviorClient(비해비어 숫자, 로봇이름)</font>\n",
    "\n",
    "###### 예시\n",
    "- SetBehaviorClient(1,\"robot_0\")\n",
    "###### 비해비어 인덱스 (19년3월2일 기준)\n",
    "- 0: ready (아무것도안함)\n",
    "- 1: lockon search behavior (움직이다가 적발견하면 락온하고 쏨. 목표로 x,y좌표받음)\n",
    "- 2: manual speed control (수동으로 움직이면서 락온함. 목표로 x,y속도랑 바라보는 방향 theta 받음. 지도 절대좌표기준임)\n",
    "- 3: hold rotate behavior (제자리에서 빙글빙글 돌다가 적발견하면 락온함. 목표로 각속도 받게 할 예정. 일단은 2로 돌음)\n",
    "- 4: hold sentry behavior (특정 방향 좌우로 45도 두리번거리다가 적발견하면 락온함. 목표로 바라볼 방향 받음)\n",
    "- 5: reload behavior (재장전함. 목표로 장전 위치 정해줘야함. ex np.array([4,4.5,-1.5707,0,0,0,0]) )\n",
    "- 6: get buff behavior (미구현)\n",
    "- 7: backboot behavior (처음시작 위치로 가서 정렬함. 목표로 처음 시작 위치 정해줘야함 np.array([1,1,0,0,0,0,0]))\n",
    "- 나머진 아직안됨\n",
    "\n",
    "\n",
    "###  <font color=blue>2. SetGoalClient(목표, 로봇이름)</font>\n",
    "###### 예시\n",
    "- goal = np.array([5,3,0,0,0,0,0])\n",
    "- SetGoalClient(goal,\"robot_0\")\n",
    "###### 기타\n",
    "- 넘파이 7차원벡터를 goal로 받음. behavior마다 쓰는 goal이 다름\n",
    "- 일반적으로 [x,y,yaw,vx,vy,v_th,etc] 혹은 [vx,vy,v_th,ax,ay,a_th,etc]로 생각하면됨\n",
    "- lockon search behavior 같은 navigation 계열은 x,y좌표만 받음. 따라서 0번, 1번 element만 채워주면됨\n",
    "- manual speed behavior같은 manual control게열은 x속도 y속도, 각도관련 받음 따라서 0 1 2 element 사용\n",
    "- hold 게열은 theta만 받음 고로 2번 element만 채워주면됨\n",
    "- 등등\n",
    "\n",
    "###  <font color=blue>3. GetInfoClient(로봇이름,확인)</font>\n",
    "###### 설명\n",
    "- 로봇의 상태(블랙보드)를 딕셔너리로 받아옴. 확인은 0은 false, 1은 true로서 일단은 적에게 맞았을 때 is hit이 true가 되는데 이걸 다시 false로 바꿔줄것이냐 아니냐를 의미함. 가령 단순히 로봇의 상태만 보기 위해서는 0을 설정하고면 되고, 실제 의사결정을 하는 디시젼노드가 이 정보를 받을 때는 적에게 맞았다는것을 확인했기 때문에 is hit을 false로 바꿔줘야 하므로 확인을 1로 설정함. 기본값은 1임 잘 모르겠으면 1로하면됨\n",
    "###### 예시\n",
    "- GetInfoClient(\"robot_0\",1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=Green>실제 예시</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "#import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as K\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth=True\n",
    "#session=tf.Session(config=config)\n",
    "import keras\n",
    "#keras.backend.set_session(session)\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/kang/catkin_ws/src/icra_roboin_decision/scripts'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "import roslib\n",
    "import numpy as np\n",
    "from icra_roboin_decision_modules.roboin_behavior_service_module import SetBehaviorClient, SetGoalClient, GetInfoClient\n",
    "rospy.init_node('decision_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "    def __init__(self, state_size):\n",
    "        self.load_model = False\n",
    "        self.action_space = ['u', 'd', 'l', 'r','ul','ur','dl','dr','enemy'] #,'back']\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.state_size = state_size\n",
    "\n",
    "        # Hyper_Parameters\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.0001\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = .99999\n",
    "        self.epsilon_min = 0.1\n",
    "        self.batch_size = 32\n",
    "        self.train_start = 2000\n",
    "\n",
    "        # Model & Target Model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        print(self.model.summary())\n",
    "        self.memory = deque(maxlen=100000)\n",
    "\n",
    "        if self.load_model:\n",
    "            self.epsilon = 0.05\n",
    "            self.model.load_weights('./save_model/DQN_Agent.h5')\n",
    "\n",
    "    # Network\n",
    "    def build_model(self):\n",
    "        with K.tf.device('/cpu:0'):\n",
    "            model = Sequential()\n",
    "            model.add(Conv1D(filters = 20, kernel_size = 1, input_shape = (self.state_size, 3),\n",
    "                             kernel_initializer = 'he_uniform', activation = 'tanh'))\n",
    "            model.add(Dense(50, activation = 'tanh', kernel_initializer = 'he_uniform'))\n",
    "            model.add(Dense(50, activation = 'tanh', kernel_initializer = 'he_uniform'))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(self.action_size, activation = 'linear'))\n",
    "            model.summary()\n",
    "            model.compile(loss = 'mse', optimizer = Adam(lr = self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # Choose Action by e-greedy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # Random Action\n",
    "            temp_rand = random.randrange(self.action_size)\n",
    "            # print(temp_rand)\n",
    "            return temp_rand\n",
    "        else:\n",
    "            # Action by model\n",
    "            # state = np.float32(state)\n",
    "            q_values = self.model.predict(state)\n",
    "            print(\"Q_Values: \", q_values)\n",
    "            return np.argmax(q_values[0])\n",
    "\n",
    "    # <state, action, reward, next_state> in Replay Memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        # state = np.reshape(state, [1, -1])\n",
    "        # next_state = np.reshape(next_state, [1, -1])\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # Random Sampling in Replay Memory, Model Training\n",
    "    def train_model(self):\n",
    "        with K.tf.device('/cpu:0'):\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "            # Random Sampling in memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            #states = [[0 for x in range(self.state_size)] for y in range(self.batch_size)]\n",
    "            states = np.zeros((self.batch_size,1 ,self.state_size,3))\n",
    "            #next_states = [[0 for x in range(self.state_size)] for y in range(self.batch_size)]\n",
    "            next_states = np.zeros((self.batch_size, 1, self.state_size,3))\n",
    "            actions, rewards, dones = [], [], []\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                states[i] = mini_batch[i][0]\n",
    "                next_states[i] = mini_batch[i][3]\n",
    "                actions.append(mini_batch[i][1])\n",
    "                rewards.append(mini_batch[i][2])\n",
    "                dones.append(mini_batch[i][4])\n",
    "\n",
    "            target = np.zeros((self.batch_size,1,4))\n",
    "            target_val = np.zeros((self.batch_size,1,4))\n",
    "            for i in range(len(states)):\n",
    "                target[i] = self.model.predict(states[i])\n",
    "                target_val[i] = self.target_model.predict(next_states[i])\n",
    "            for i in range(self.batch_size):\n",
    "                if dones[i]:\n",
    "                    target[i][0][actions[i]] = rewards[i]\n",
    "                else:\n",
    "                    target[i][0][actions[i]] = rewards[i] + self.discount_factor * np.amax(target_val[i])\n",
    "\n",
    "            states = np.squeeze(states)\n",
    "            target = np.squeeze(target)\n",
    "\n",
    "            self.model.fit(states, target, batch_size=self.batch_size,\n",
    "                           epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards ={}\n",
    "temp_info = GetInfoClient(\"robot_0\",1)\n",
    "rewards['enemy_detect'] = temp_info['how_many_enemies_detected'] * 1\n",
    "rewards['is_hit'] = temp_info['is_hit'] * -1\n",
    "# rewards['my_health'] = temp_info['my_health'] * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reset\n",
    "def robo_reset():\n",
    "    behav_=7\n",
    "    SetBehaviorClient(behav_,\"robot_0\")\n",
    "    SetBehaviorClient(behav_,\"robot_1\")\n",
    "    goal_ = np.array([1,1,0,0,0,0,0])\n",
    "    SetGoalClient(goal_,\"robot_0\")\n",
    "    SetGoalClient(goal_,\"robot_1\")\n",
    "    reset = True\n",
    "    while reset:\n",
    "        check_pos0 = GetInfoClient(\"robot_0\",1)[\"my_pose\"][\"pose\"][\"position\"]\n",
    "        check_pos1 = GetInfoClient(\"robot_1\",1)[\"my_pose\"][\"pose\"][\"position\"]\n",
    "        pos0_norm = pow(pow(check_pos0['x'],2)+pow(check_pos0['y'],2),0.5)\n",
    "        pos1_norm = pow(pow(check_pos1['x'],2)+pow(check_pos1['y'],2),0.5)\n",
    "        print pos0_norm, pos1_norm\n",
    "        if (pos0_norm<pow(2.2, 0.5)) and (pos1_norm<pow(2.2, 0.5)):\n",
    "            reset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37676793479 4.00384151883\n",
      "4.31402332869 3.99971412525\n",
      "4.11811017227 4.00129368546\n",
      "3.8277084674 4.00367884012\n",
      "3.51418744359 3.99203278782\n",
      "3.22322539715 3.90824158256\n",
      "2.92103823701 3.74526296279\n",
      "2.62209655913 3.56443176866\n",
      "2.32425384107 3.39310554494\n",
      "2.02401473526 3.18542881669\n",
      "1.74833415575 2.9607745187\n",
      "1.53187977113 2.71762611482\n",
      "1.42175222184 2.52360395338\n",
      "1.37564037771 2.35896386908\n",
      "1.34204450929 2.17665543588\n",
      "1.3394864209 2.01303910291\n",
      "1.33965127665 1.84744268438\n",
      "1.33965127665 1.67023013458\n",
      "1.33965127665 1.50750847616\n",
      "1.33965127665 1.41521735827\n"
     ]
    }
   ],
   "source": [
    "robo_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(robot, action):\n",
    "    action_space = ['u', 'd', 'l', 'r','ul','ur','dl','dr','enemy'] #,'back']\n",
    "    movement = action_space[action]\n",
    "    \n",
    "    move_const = 0.5\n",
    "    SetBehaviorClient(1, robot)\n",
    "    temp_info = GetInfoClient(robot,1)\n",
    "    my_pos = temp_info[\"my_pose\"][\"pose\"][\"position\"]\n",
    "    enemy_pos = temp_info[\"enemy_pose1\"][\"pose\"][\"position\"]\n",
    "    goal = np.array([my_pos['x'], my_pos['y'], 0, 0, 0, 0, 0])\n",
    "    root2 = pow(2, 0.5)\n",
    "    if movement=='u':\n",
    "        goal += np.array([0,1,0,0,0,0,0]) * move_const\n",
    "    elif movement=='d':\n",
    "        goal += np.array([0,-1,0,0,0,0,0]) * move_const\n",
    "    elif movement=='l':\n",
    "        goal += np.array([-1,0,0,0,0,0,0]) * move_const\n",
    "    elif movement=='r':\n",
    "        goal += np.array([1,0,0,0,0,0,0]) * move_const\n",
    "    elif movement=='ul':\n",
    "        goal += np.array([-root2,root2,0,0,0,0,0]) * move_const\n",
    "    elif movement=='ur':\n",
    "        goal += np.array([root2,root2,0,0,0,0,0]) * move_const\n",
    "    elif movement=='dl':\n",
    "        goal += np.array([-root2,-root2,0,0,0,0,0]) * move_const\n",
    "    elif movement=='dr':\n",
    "        goal += np.array([root2,-root2,0,0,0,0,0]) * move_const\n",
    "    elif movement=='enemy':\n",
    "        goal = np.array([enemy_pos['x'],enemy_pos['y'],0,0,0,0,0])\n",
    "    elif movement=='back':\n",
    "        goal = np.array([1,1,0,0,0,0,0])\n",
    "    SetGoalClient(goal, robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_43 (Conv1D)           (None, 6, 20)             80        \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 6, 50)             1050      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6, 50)             2550      \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 9)                 2709      \n",
      "=================================================================\n",
      "Total params: 6,389\n",
      "Trainable params: 6,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 6, 20)             80        \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 6, 50)             1050      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 6, 50)             2550      \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 9)                 2709      \n",
      "=================================================================\n",
      "Total params: 6,389\n",
      "Trainable params: 6,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_43 (Conv1D)           (None, 6, 20)             80        \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 6, 50)             1050      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 6, 50)             2550      \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 9)                 2709      \n",
      "=================================================================\n",
      "Total params: 6,389\n",
      "Trainable params: 6,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "2.42068988571 1.06130003145\n",
      "2.38220290309 1.08962296548\n",
      "2.24313206424 1.19925572457\n",
      "2.03263618032 1.29593671475\n",
      "1.85372983188 1.35950890551\n",
      "1.69466377655 1.38459688482\n",
      "1.55299938386 1.38458284984\n",
      "1.44423626403 1.38458284984\n",
      "Step :  10 time :  8006 ms score :  -1.0\n",
      "Step :  20 time :  7991 ms score :  -2.0\n",
      "Step :  30 time :  8003 ms score :  -3.0\n",
      "Step :  40 time :  7991 ms score :  -4.0\n",
      "Step :  50 time :  8000 ms score :  -5.0\n",
      "Step :  60 time :  7993 ms score :  -6.0\n",
      "Step :  70 time :  7996 ms score :  -7.0\n",
      "Step :  80 time :  8004 ms score :  -1.0\n",
      "Step :  90 time :  7993 ms score :  8.0\n",
      "Step :  100 time :  8005 ms score :  17.0\n",
      "Step :  110 time :  7917 ms score :  23.0\n",
      "Step :  120 time :  8000 ms score :  30.0\n",
      "Step :  130 time :  7990 ms score :  39.0\n",
      "Step :  140 time :  8002 ms score :  40.0\n",
      "Step :  150 time :  7998 ms score :  39.0\n",
      "Step :  160 time :  8000 ms score :  38.0\n",
      "Step :  170 time :  7994 ms score :  37.0\n",
      "Step :  180 time :  8000 ms score :  36.0\n",
      "Step :  190 time :  8001 ms score :  35.0\n",
      "Step :  200 time :  8000 ms score :  34.0\n",
      "Step :  210 time :  7823 ms score :  33.0\n",
      "Step :  220 time :  7997 ms score :  32.0\n",
      "Step :  230 time :  8000 ms score :  31.0\n",
      "Step :  240 time :  8004 ms score :  30.0\n",
      "Step :  250 time :  7992 ms score :  29.0\n",
      "Step :  260 time :  7997 ms score :  28.0\n",
      "Step :  270 time :  8103 ms score :  27.0\n",
      "Step :  280 time :  7991 ms score :  26.0\n",
      "Step :  290 time :  8003 ms score :  25.0\n",
      "Step :  300 time :  7997 ms score :  24.0\n",
      "Step :  310 time :  7920 ms score :  23.0\n",
      "Step :  320 time :  8004 ms score :  22.0\n",
      "Step :  330 time :  7995 ms score :  21.0\n",
      "Step :  340 time :  7994 ms score :  20.0\n",
      "Step :  350 time :  7997 ms score :  19.0\n",
      "Step :  360 time :  8000 ms score :  18.0\n",
      "Step :  370 time :  8001 ms score :  17.0\n",
      "Step :  380 time :  8000 ms score :  16.0\n",
      "Step :  390 time :  7999 ms score :  15.0\n",
      "Step :  400 time :  7999 ms score :  14.0\n",
      "Step :  410 time :  7911 ms score :  13.0\n",
      "Step :  420 time :  7999 ms score :  12.0\n",
      "Step :  430 time :  8001 ms score :  11.0\n",
      "Step :  440 time :  7997 ms score :  10.0\n",
      "Step :  450 time :  8002 ms score :  9.0\n",
      "Step :  460 time :  8002 ms score :  8.0\n",
      "Step :  470 time :  7994 ms score :  7.0\n",
      "Step :  480 time :  8003 ms score :  6.0\n",
      "Step :  490 time :  7993 ms score :  5.0\n",
      "('episode : ', 1, 'step : ', 500, 'Replay_Memory : ', 1000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "2.68675460105 6.12992185884\n",
      "2.63645747111 5.98870694264\n",
      "2.48848844182 5.7144460926\n",
      "2.30237786451 5.38929003851\n",
      "2.13822849744 5.07208857363\n",
      "1.97502294902 4.76322345154\n",
      "1.80187681083 4.47119750745\n",
      "1.6179808621 4.19989807664\n",
      "1.4814008976 3.94778625015\n",
      "1.38073437298 3.6806665166\n",
      "1.38078411496 3.35500627551\n",
      "1.3807435634 2.98144606702\n",
      "1.3807435634 2.60850862651\n",
      "1.3807435634 2.24179054615\n",
      "1.3807435634 1.9325398987\n",
      "1.3807435634 1.72795198449\n",
      "1.3807435634 1.58968644999\n",
      "1.3807435634 1.4705309603\n",
      "Step :  500 time :  13301 ms score :  -16.0\n",
      "Step :  10 time :  7967 ms score :  -1.0\n",
      "Step :  20 time :  7997 ms score :  -2.0\n",
      "Step :  30 time :  7998 ms score :  -3.0\n",
      "Step :  40 time :  8002 ms score :  -4.0\n",
      "Step :  50 time :  7995 ms score :  -5.0\n",
      "Step :  60 time :  8001 ms score :  -6.0\n",
      "Step :  70 time :  7996 ms score :  -7.0\n",
      "Step :  80 time :  7995 ms score :  -8.0\n",
      "Step :  90 time :  8007 ms score :  -9.0\n",
      "Step :  100 time :  7994 ms score :  -10.0\n",
      "Step :  110 time :  7961 ms score :  -11.0\n",
      "Step :  120 time :  7998 ms score :  -12.0\n",
      "Step :  130 time :  8002 ms score :  -13.0\n",
      "Step :  140 time :  8000 ms score :  -14.0\n",
      "Step :  150 time :  7996 ms score :  -15.0\n",
      "Step :  160 time :  7997 ms score :  -16.0\n",
      "Step :  170 time :  8003 ms score :  -17.0\n",
      "Step :  180 time :  7996 ms score :  -18.0\n",
      "Step :  190 time :  7997 ms score :  -19.0\n",
      "Step :  200 time :  7995 ms score :  -20.0\n",
      "Step :  210 time :  7996 ms score :  -21.0\n",
      "Step :  220 time :  7999 ms score :  -22.0\n",
      "Step :  230 time :  8000 ms score :  -23.0\n",
      "Step :  240 time :  7997 ms score :  -24.0\n",
      "Step :  250 time :  7898 ms score :  -25.0\n",
      "Step :  260 time :  7999 ms score :  -26.0\n",
      "Step :  270 time :  8000 ms score :  -27.0\n",
      "Step :  280 time :  7994 ms score :  -28.0\n",
      "Step :  290 time :  8000 ms score :  -29.0\n",
      "Step :  300 time :  8001 ms score :  -30.0\n",
      "Step :  310 time :  7912 ms score :  -31.0\n",
      "Step :  320 time :  7994 ms score :  -32.0\n",
      "Step :  330 time :  8001 ms score :  -33.0\n",
      "Step :  340 time :  7995 ms score :  -34.0\n",
      "Step :  350 time :  7999 ms score :  -35.0\n",
      "Step :  360 time :  8002 ms score :  -36.0\n",
      "Step :  370 time :  7998 ms score :  -37.0\n",
      "Step :  380 time :  7996 ms score :  -38.0\n",
      "Step :  390 time :  8000 ms score :  -39.0\n",
      "Step :  400 time :  7995 ms score :  -40.0\n",
      "Step :  410 time :  7905 ms score :  -41.0\n",
      "Step :  420 time :  8099 ms score :  -42.0\n",
      "Step :  430 time :  7999 ms score :  -43.0\n",
      "Step :  440 time :  7998 ms score :  -44.0\n",
      "Step :  450 time :  7996 ms score :  -45.0\n",
      "Step :  460 time :  8003 ms score :  -46.0\n",
      "Step :  470 time :  7997 ms score :  -47.0\n",
      "Step :  480 time :  7997 ms score :  -48.0\n",
      "Step :  490 time :  8004 ms score :  -49.0\n",
      "('episode : ', 2, 'step : ', 500, 'Replay_Memory : ', 2000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "3.25875031364 6.14758828805\n",
      "3.20429036626 6.08550878749\n",
      "3.04467362596 5.90118663934\n",
      "2.78794640202 5.64731799832\n",
      "2.46645649252 5.39676546952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15300090244 5.16937813908\n",
      "1.88461003619 4.95972166193\n",
      "1.56418028117 4.6645650736\n",
      "1.44391488247 4.47636811435\n",
      "1.39822066824 4.29179575168\n",
      "1.37046740873 4.11098987054\n",
      "1.35031583927 3.92026106013\n",
      "1.35028992894 3.7193122697\n",
      "1.35037098182 3.51954442807\n",
      "1.35037098182 3.33088309372\n",
      "1.35037098182 3.1290182427\n",
      "1.35037098182 2.9087662058\n",
      "1.35037098182 2.65613143639\n",
      "1.35037098182 2.40635686391\n",
      "1.35037098182 2.18964901161\n",
      "1.35037098182 2.01062903074\n",
      "1.35037098182 1.84719021444\n",
      "1.35037098182 1.69354988414\n",
      "1.35037098182 1.55482888848\n",
      "1.35037098182 1.4641603171\n",
      "Step :  500 time :  13496 ms score :  -70.0\n",
      "Step :  10 time :  7998 ms score :  -1.0\n",
      "Step :  20 time :  7998 ms score :  -2.0\n",
      "Step :  30 time :  7999 ms score :  -3.0\n",
      "Step :  40 time :  7995 ms score :  -4.0\n",
      "Step :  50 time :  8001 ms score :  -5.0\n",
      "Step :  60 time :  8095 ms score :  -6.0\n",
      "Step :  70 time :  7998 ms score :  -7.0\n",
      "Step :  80 time :  7997 ms score :  -8.0\n",
      "Step :  90 time :  8003 ms score :  -9.0\n",
      "Step :  100 time :  7997 ms score :  -10.0\n",
      "Step :  110 time :  7922 ms score :  -11.0\n",
      "Step :  120 time :  7999 ms score :  -12.0\n",
      "Step :  130 time :  7997 ms score :  -13.0\n",
      "Step :  140 time :  8001 ms score :  -14.0\n",
      "Step :  150 time :  7998 ms score :  -15.0\n",
      "Step :  160 time :  7998 ms score :  -16.0\n",
      "Step :  170 time :  7998 ms score :  -17.0\n",
      "Step :  180 time :  7997 ms score :  -18.0\n",
      "Step :  190 time :  8004 ms score :  -19.0\n",
      "Step :  200 time :  7994 ms score :  -20.0\n",
      "Step :  210 time :  7990 ms score :  -21.0\n",
      "Step :  220 time :  7989 ms score :  -22.0\n",
      "Step :  230 time :  8003 ms score :  -23.0\n",
      "Step :  240 time :  7999 ms score :  -24.0\n",
      "Step :  250 time :  7992 ms score :  -25.0\n",
      "Step :  260 time :  7993 ms score :  -26.0\n",
      "Step :  270 time :  7995 ms score :  -27.0\n",
      "Step :  280 time :  8001 ms score :  -28.0\n",
      "Step :  290 time :  8007 ms score :  -29.0\n",
      "Step :  300 time :  7996 ms score :  -30.0\n",
      "Step :  310 time :  7955 ms score :  -31.0\n",
      "Step :  320 time :  7998 ms score :  -32.0\n",
      "Step :  330 time :  7997 ms score :  -33.0\n",
      "Step :  340 time :  7998 ms score :  -34.0\n",
      "Step :  350 time :  8004 ms score :  -35.0\n",
      "Step :  360 time :  7996 ms score :  -36.0\n",
      "Step :  370 time :  7995 ms score :  -37.0\n",
      "Step :  380 time :  8001 ms score :  -38.0\n",
      "Step :  390 time :  7996 ms score :  -39.0\n",
      "Step :  400 time :  8005 ms score :  -40.0\n",
      "Step :  410 time :  7883 ms score :  -41.0\n",
      "Step :  420 time :  7997 ms score :  -42.0\n",
      "Step :  430 time :  7997 ms score :  -43.0\n",
      "Step :  440 time :  7901 ms score :  -44.0\n",
      "Step :  450 time :  7996 ms score :  -45.0\n",
      "Step :  460 time :  7998 ms score :  -46.0\n",
      "Step :  470 time :  7997 ms score :  -47.0\n",
      "Step :  480 time :  8007 ms score :  -48.0\n",
      "Step :  490 time :  7992 ms score :  -49.0\n",
      "('episode : ', 3, 'step : ', 500, 'Replay_Memory : ', 3000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "4.56547686962 5.91068546054\n",
      "4.4752964051 5.86398840242\n",
      "4.29310441821 5.74953876732\n",
      "4.10805884781 5.60330304815\n",
      "3.92436313742 5.42764504085\n",
      "3.74047903039 5.28106833202\n",
      "3.55586699723 5.16624228068\n",
      "3.36457492244 5.11586797983\n",
      "3.16349006076 4.95742705156\n",
      "2.94179863193 4.69884536454\n",
      "2.69152274983 4.38624801194\n",
      "2.44539630287 4.0997575664\n",
      "2.23097380301 3.80631552792\n",
      "2.05037190951 3.49226725201\n",
      "1.89610735429 3.16976458454\n",
      "1.75134472488 2.80580251168\n",
      "1.60384366894 2.45232949619\n",
      "1.47102246994 2.17090627515\n",
      "1.39373694572 1.93146214787\n",
      "1.36263536513 1.72905851765\n",
      "1.36174929 1.56395309239\n",
      "1.36174929 1.4372663557\n",
      "Step :  500 time :  12796 ms score :  -70.0\n",
      "Step :  10 time :  7932 ms score :  -1.0\n",
      "Step :  20 time :  7998 ms score :  -2.0\n",
      "Step :  30 time :  7992 ms score :  -3.0\n",
      "Step :  40 time :  8001 ms score :  -4.0\n",
      "Step :  50 time :  7996 ms score :  -5.0\n",
      "Step :  60 time :  7998 ms score :  -6.0\n",
      "Step :  70 time :  8001 ms score :  -7.0\n",
      "Step :  80 time :  7996 ms score :  -8.0\n",
      "Step :  90 time :  7997 ms score :  -9.0\n",
      "Step :  100 time :  7997 ms score :  -10.0\n",
      "Step :  110 time :  7915 ms score :  -11.0\n",
      "Step :  120 time :  7998 ms score :  -12.0\n",
      "Step :  130 time :  7982 ms score :  -13.0\n",
      "Step :  140 time :  8005 ms score :  -14.0\n",
      "Step :  150 time :  7992 ms score :  -15.0\n",
      "Step :  160 time :  8003 ms score :  -16.0\n",
      "Step :  170 time :  7997 ms score :  -17.0\n",
      "Step :  180 time :  8002 ms score :  -18.0\n",
      "Step :  190 time :  7991 ms score :  -19.0\n",
      "Step :  200 time :  8000 ms score :  -20.0\n",
      "Step :  210 time :  7907 ms score :  -21.0\n",
      "Step :  220 time :  7998 ms score :  -22.0\n",
      "Step :  230 time :  8000 ms score :  -23.0\n",
      "Step :  240 time :  7996 ms score :  -24.0\n",
      "Step :  250 time :  8004 ms score :  -25.0\n",
      "Step :  260 time :  7994 ms score :  -26.0\n",
      "Step :  270 time :  8012 ms score :  -27.0\n",
      "Step :  280 time :  7986 ms score :  -28.0\n",
      "Step :  290 time :  8000 ms score :  -29.0\n",
      "Step :  300 time :  8002 ms score :  -30.0\n",
      "Step :  310 time :  7927 ms score :  -31.0\n",
      "Step :  320 time :  7991 ms score :  -32.0\n",
      "Step :  330 time :  8002 ms score :  -33.0\n",
      "Step :  340 time :  7997 ms score :  -34.0\n",
      "Step :  350 time :  7996 ms score :  -35.0\n",
      "Step :  360 time :  8013 ms score :  -36.0\n",
      "Step :  370 time :  7985 ms score :  -37.0\n",
      "Step :  380 time :  8002 ms score :  -38.0\n",
      "Step :  390 time :  8003 ms score :  -39.0\n",
      "Step :  400 time :  7994 ms score :  -40.0\n",
      "Step :  410 time :  7905 ms score :  -41.0\n",
      "Step :  420 time :  8002 ms score :  -42.0\n",
      "Step :  430 time :  7997 ms score :  -43.0\n",
      "Step :  440 time :  7997 ms score :  -44.0\n",
      "Step :  450 time :  8001 ms score :  -45.0\n",
      "Step :  460 time :  8001 ms score :  -46.0\n",
      "Step :  470 time :  7991 ms score :  -47.0\n",
      "Step :  480 time :  8001 ms score :  -48.0\n",
      "Step :  490 time :  7995 ms score :  -49.0\n",
      "('episode : ', 4, 'step : ', 500, 'Replay_Memory : ', 4000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "6.6382898522 6.9259071992\n",
      "6.68858728465 6.89282574137\n",
      "6.82127717691 6.79434359438\n",
      "6.96007194133 6.64006472199\n",
      "7.0271577363 6.42594694767\n",
      "7.01110080518 6.20597867842\n",
      "6.89606063572 6.01902484717\n",
      "6.67152377964 5.80648295742\n",
      "6.41208515543 5.58337796017\n",
      "6.13515168096 5.34479218067\n",
      "5.86996789691 5.1223088482\n",
      "5.54723506078 4.87160148304\n",
      "5.23564135376 4.63436484089\n",
      "4.93133495021 4.42650500242\n",
      "4.63871777171 4.22104920243\n",
      "4.35090021873 4.0040501507\n",
      "4.07968891787 3.78273293576\n",
      "3.78476480916 3.57193147568\n",
      "3.46104640626 3.32587879458\n",
      "3.1028036564 3.01265019403\n",
      "2.73632972436 2.66797533674\n",
      "2.40412783346 2.38065946838\n",
      "2.08410070699 2.15393104886\n",
      "1.77345700755 1.97068856711\n",
      "1.51917981959 1.81675864317\n",
      "1.34005483438 1.65745925704\n",
      "1.23981904907 1.51081988905\n",
      "1.18625020375 1.42002362761\n",
      "Step :  500 time :  13998 ms score :  -70.0\n",
      "Step :  10 time :  7879 ms score :  -1.0\n",
      "Step :  20 time :  7999 ms score :  -2.0\n",
      "Step :  30 time :  7997 ms score :  -3.0\n",
      "Step :  40 time :  8099 ms score :  -4.0\n",
      "Step :  50 time :  7998 ms score :  -5.0\n",
      "Step :  60 time :  7999 ms score :  -6.0\n",
      "Step :  70 time :  8000 ms score :  -7.0\n",
      "Step :  80 time :  7894 ms score :  -8.0\n",
      "Step :  90 time :  8005 ms score :  -9.0\n",
      "Step :  100 time :  7993 ms score :  -10.0\n",
      "Step :  110 time :  7967 ms score :  -11.0\n",
      "Step :  120 time :  8100 ms score :  -12.0\n",
      "Step :  130 time :  8008 ms score :  -13.0\n",
      "Step :  140 time :  7993 ms score :  -14.0\n",
      "Step :  150 time :  7996 ms score :  -15.0\n",
      "Step :  160 time :  7996 ms score :  -16.0\n",
      "Step :  170 time :  7992 ms score :  -17.0\n",
      "Step :  180 time :  8006 ms score :  -18.0\n",
      "Step :  190 time :  7992 ms score :  -19.0\n",
      "Step :  200 time :  8007 ms score :  -20.0\n",
      "Step :  210 time :  7985 ms score :  -21.0\n",
      "Step :  220 time :  8003 ms score :  -22.0\n",
      "Step :  230 time :  7997 ms score :  -23.0\n",
      "Step :  240 time :  7996 ms score :  -24.0\n",
      "Step :  250 time :  7995 ms score :  -25.0\n",
      "Step :  260 time :  8002 ms score :  -26.0\n",
      "Step :  270 time :  7994 ms score :  -27.0\n",
      "Step :  280 time :  7998 ms score :  -28.0\n",
      "Step :  290 time :  8000 ms score :  -29.0\n",
      "Step :  300 time :  7997 ms score :  -30.0\n",
      "Step :  310 time :  8000 ms score :  -31.0\n",
      "Step :  320 time :  8004 ms score :  -32.0\n",
      "Step :  330 time :  8092 ms score :  -33.0\n",
      "Step :  340 time :  7998 ms score :  -34.0\n",
      "Step :  350 time :  8007 ms score :  -35.0\n",
      "Step :  360 time :  7988 ms score :  -36.0\n",
      "Step :  370 time :  8007 ms score :  -37.0\n",
      "Step :  380 time :  7993 ms score :  -38.0\n",
      "Step :  390 time :  7996 ms score :  -39.0\n",
      "Step :  400 time :  7999 ms score :  -40.0\n",
      "Step :  410 time :  7909 ms score :  -41.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  420 time :  8000 ms score :  -42.0\n",
      "Step :  430 time :  7993 ms score :  -43.0\n",
      "Step :  440 time :  8001 ms score :  -44.0\n",
      "Step :  450 time :  7899 ms score :  -45.0\n",
      "Step :  460 time :  7999 ms score :  -46.0\n",
      "Step :  470 time :  8007 ms score :  -47.0\n",
      "Step :  480 time :  7994 ms score :  -48.0\n",
      "Step :  490 time :  7996 ms score :  -49.0\n",
      "('episode : ', 5, 'step : ', 500, 'Replay_Memory : ', 5000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "2.37087201236 7.16748179243\n",
      "2.33367189235 7.1018248055\n",
      "2.22241264999 6.92485099452\n",
      "2.05214598336 6.7359127637\n",
      "1.81116166647 6.55453453831\n",
      "1.54365125836 6.38837065718\n",
      "1.37518595422 6.22482947076\n",
      "1.32556257254 6.00386132567\n",
      "1.33162430057 5.72829849911\n",
      "1.34692935191 5.42563659542\n",
      "1.35615417075 5.1100328377\n",
      "1.35615417075 4.94249978702\n",
      "1.35615417075 4.7576945075\n",
      "1.35615417075 4.52155419053\n",
      "1.35615417075 4.27659446755\n",
      "1.35615417075 3.99041819836\n",
      "1.35615417075 3.69032400516\n",
      "1.35615417075 3.33634546066\n",
      "1.35615417075 2.97242082317\n",
      "1.35615417075 2.63301705293\n",
      "1.35615417075 2.31046238494\n",
      "1.35615417075 2.04101792678\n",
      "1.35615417075 1.79046315587\n",
      "1.35615417075 1.58344392513\n",
      "1.35615417075 1.43193555995\n",
      "Step :  500 time :  13398 ms score :  -70.0\n",
      "Step :  10 time :  7994 ms score :  -1.0\n",
      "Step :  20 time :  7999 ms score :  -2.0\n",
      "Step :  30 time :  7998 ms score :  -3.0\n",
      "Step :  40 time :  7998 ms score :  -4.0\n",
      "Step :  50 time :  8001 ms score :  -5.0\n",
      "Step :  60 time :  7993 ms score :  -6.0\n",
      "Step :  70 time :  8000 ms score :  -7.0\n",
      "Step :  80 time :  7997 ms score :  -8.0\n",
      "Step :  90 time :  7993 ms score :  -9.0\n",
      "Step :  100 time :  7998 ms score :  -10.0\n",
      "Step :  110 time :  7999 ms score :  -11.0\n",
      "Step :  120 time :  8001 ms score :  -12.0\n",
      "Step :  130 time :  8006 ms score :  -13.0\n",
      "Step :  140 time :  7999 ms score :  -14.0\n",
      "Step :  150 time :  7989 ms score :  -15.0\n",
      "Step :  160 time :  8000 ms score :  -16.0\n",
      "Step :  170 time :  7989 ms score :  -17.0\n",
      "Step :  180 time :  7898 ms score :  -18.0\n",
      "Step :  190 time :  7993 ms score :  -19.0\n",
      "Step :  200 time :  7999 ms score :  -20.0\n",
      "Step :  210 time :  7991 ms score :  -21.0\n",
      "Step :  220 time :  8000 ms score :  -22.0\n",
      "Step :  230 time :  7904 ms score :  -23.0\n",
      "Step :  240 time :  7994 ms score :  -24.0\n",
      "Step :  250 time :  8001 ms score :  -25.0\n",
      "Step :  260 time :  7997 ms score :  -26.0\n",
      "Step :  270 time :  8001 ms score :  -27.0\n",
      "Step :  280 time :  7995 ms score :  -28.0\n",
      "Step :  290 time :  7992 ms score :  -29.0\n",
      "Step :  300 time :  8000 ms score :  -30.0\n",
      "Step :  310 time :  7992 ms score :  -31.0\n",
      "Step :  320 time :  7991 ms score :  -32.0\n",
      "Step :  330 time :  7997 ms score :  -33.0\n",
      "Step :  340 time :  7898 ms score :  -34.0\n",
      "Step :  350 time :  7999 ms score :  -35.0\n",
      "Step :  360 time :  7999 ms score :  -36.0\n",
      "Step :  370 time :  7999 ms score :  -37.0\n",
      "Step :  380 time :  7999 ms score :  -38.0\n",
      "Step :  390 time :  7993 ms score :  -39.0\n",
      "Step :  400 time :  7995 ms score :  -40.0\n",
      "Step :  410 time :  7908 ms score :  -41.0\n",
      "Step :  420 time :  7997 ms score :  -42.0\n",
      "Step :  430 time :  7999 ms score :  -43.0\n",
      "Step :  440 time :  7799 ms score :  -44.0\n",
      "Step :  450 time :  7999 ms score :  -45.0\n",
      "Step :  460 time :  7999 ms score :  -46.0\n",
      "Step :  470 time :  8104 ms score :  -47.0\n",
      "Step :  480 time :  7978 ms score :  -48.0\n",
      "Step :  490 time :  8097 ms score :  -49.0\n",
      "('episode : ', 6, 'step : ', 500, 'Replay_Memory : ', 6000, 'global_step : ', 500, 'epsilon : ', 1)\n",
      "1.64509988098 6.32792060273\n",
      "1.62039110686 6.26397715058\n",
      "1.53327249515 6.08906569405\n",
      "1.44056825254 5.81445430782\n",
      "1.38823592488 5.52042254263\n",
      "1.37261019876 5.18650181645\n",
      "1.37260888263 4.89507981519\n",
      "1.37260888263 4.60307325792\n",
      "1.37260888263 4.33073783516\n",
      "1.37260888263 4.05510307557\n",
      "1.37260888263 3.77987184295\n",
      "1.37260888263 3.48650101005\n",
      "1.37260888263 3.16211243056\n",
      "1.37260888263 2.81033249283\n",
      "1.37260888263 2.47021182591\n",
      "1.37260888263 2.18893112894\n",
      "1.37260888263 1.9086807795\n",
      "1.37260888263 1.66535953132\n",
      "1.37260888263 1.51778169379\n",
      "1.37260888263 1.44362065676\n",
      "Step :  500 time :  12398 ms score :  -70.0\n",
      "Step :  10 time :  7982 ms score :  -1.0\n",
      "Step :  20 time :  7993 ms score :  -2.0\n",
      "Step :  30 time :  7999 ms score :  -3.0\n",
      "Step :  40 time :  7996 ms score :  -4.0\n",
      "Step :  50 time :  7997 ms score :  -5.0\n",
      "Step :  60 time :  8004 ms score :  -6.0\n",
      "Step :  70 time :  7996 ms score :  -7.0\n",
      "Step :  80 time :  7999 ms score :  -8.0\n",
      "Step :  90 time :  8002 ms score :  -9.0\n",
      "Step :  100 time :  7997 ms score :  -10.0\n",
      "Step :  110 time :  7936 ms score :  -11.0\n",
      "Step :  120 time :  7997 ms score :  -12.0\n",
      "Step :  130 time :  7999 ms score :  -13.0\n",
      "Step :  140 time :  7998 ms score :  -14.0\n",
      "Step :  150 time :  8002 ms score :  -15.0\n",
      "Step :  160 time :  7996 ms score :  -16.0\n",
      "Step :  170 time :  8001 ms score :  -17.0\n",
      "Step :  180 time :  7997 ms score :  -18.0\n",
      "Step :  190 time :  8005 ms score :  -19.0\n",
      "Step :  200 time :  7993 ms score :  -20.0\n",
      "Step :  210 time :  7920 ms score :  -21.0\n",
      "Step :  220 time :  8100 ms score :  -22.0\n",
      "Step :  230 time :  8000 ms score :  -23.0\n",
      "Step :  240 time :  7997 ms score :  -24.0\n",
      "Step :  250 time :  8001 ms score :  -25.0\n",
      "Step :  260 time :  7996 ms score :  -26.0\n",
      "Step :  270 time :  7899 ms score :  -27.0\n",
      "Step :  280 time :  7998 ms score :  -28.0\n",
      "Step :  290 time :  7999 ms score :  -29.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-fa9313a87aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#time.sleep(0.05)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"robot_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"robot_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnext_state0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"robot_0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0765924379dc>\u001b[0m in \u001b[0;36mmove\u001b[0;34m(robot, action)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmovement\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'back'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgoal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mSetGoalClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/kang/catkin_ws/src/icra_roboin_decision/scripts/icra_roboin_decision_modules/roboin_behavior_service_module.pyc\u001b[0m in \u001b[0;36mSetGoalClient\u001b[0;34m(goal_numpy, robot_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServiceProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobot_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/behavior_node/goal_select_service\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSetGoal_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServiceException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/impl/tcpros_service.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0musually\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtype\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_service_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/impl/tcpros_service.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"service [%s] returned no response\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.pyc\u001b[0m in \u001b[0;36mreceive_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg_queue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat_bytes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrecv_buff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuff_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat_num_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_queue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#STATS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# set the _connection_header field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/impl/tcpros_base.pyc\u001b[0m in \u001b[0;36mrecv_buff\u001b[0;34m(sock, b, buff_size)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_info(robot):\n",
    "    temp_info = GetInfoClient(robot,1)\n",
    "    rewards['enemy_detect'] = temp_info['how_many_enemies_detected'] * 1\n",
    "    rewards['is_hit'] = temp_info['is_hit'] * -1\n",
    "    enemy1_position = temp_info['enemy_pose1']['pose']['position']\n",
    "    enemy1_position = np.array([enemy1_position['x'],enemy1_position['y']]) * 0.1\n",
    "    my_position = temp_info['my_pose']['pose']['position']\n",
    "    my_position = np.array([my_position['x'],my_position['y']]) * 0.1\n",
    "    #reward is a number\n",
    "    reward = rewards['enemy_detect']+rewards['is_hit']\n",
    "    reward -= 0.05\n",
    "    state = np.append(np.append(np.append(my_position, enemy1_position), temp_info['how_many_enemies_detected']), reward)\n",
    "    return state,reward\n",
    "\n",
    "state_size = 6 # len(state)\n",
    "agent = DQN_Agent(state_size)\n",
    "episode = 100\n",
    "scores, episodes = [], []\n",
    "# get 1st state\n",
    "state0, _ = get_info(\"robot_0\")\n",
    "state1, _ = get_info(\"robot_1\")\n",
    "robo_reset()\n",
    "for e in range(1,episode+1):\n",
    "    done = False\n",
    "    score = 0\n",
    "    step = 0\n",
    "    global_step = 0\n",
    "    step_term = 0\n",
    "    while not done:\n",
    "        step += 1\n",
    "        global_step += 1\n",
    "        start_time = time.time()\n",
    "        onestep_start = time.time()\n",
    "        \n",
    "        action0 = agent.get_action(state0)\n",
    "        action1 = agent.get_action(state1)\n",
    "        \n",
    "        #time.sleep(0.05)\n",
    "        move(\"robot_0\", action0)\n",
    "        move(\"robot_1\", action1)\n",
    "        next_state0, reward0 = get_info(\"robot_0\")\n",
    "        next_state1, reward1 = get_info(\"robot_1\")\n",
    "        #print(reward0, reward1)\n",
    "        if step == 500:\n",
    "            reward0 -= 10\n",
    "            reward1 -= 10\n",
    "            done = True\n",
    "        agent.append_sample(state0,action0,reward0,next_state0,done)\n",
    "        agent.append_sample(state1,action1,reward1,next_state1,done)\n",
    "\n",
    "            \n",
    "        score += reward0\n",
    "        score += reward1\n",
    "        \n",
    "        state0 = copy.deepcopy(next_state0)\n",
    "        state1 = copy.deepcopy(next_state1)\n",
    "        \n",
    "        if len(agent.memory) >= agent.train_start:\n",
    "            agent.train_model()\n",
    "        \n",
    "        if done:\n",
    "            agent.update_target_model()\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            end_time = time.time()\n",
    "            print (\"episode : \", e, \"step : \", step, \"Replay_Memory : \", len(agent.memory),\n",
    "                   'global_step : ', global_step, 'epsilon : ', agent.epsilon)\n",
    "            robo_reset()\n",
    "                \n",
    "        onestep_end=time.time()\n",
    "        step_time = onestep_end - onestep_start\n",
    "        step_term += step_time\n",
    "        if step % 10 == 0:\n",
    "            print 'Step : ', step, 'time : ', int(step_term*1000), 'ms', 'score : ', score\n",
    "            step_term=0\n",
    "        if (global_step % 100 == 0) or (e == EPISODES):\n",
    "            pylab.plot(episodes, scores, 'olive')\n",
    "            pylab.savefig(\"./save_graph/DQN_Agent.png\")\n",
    "            \n",
    "    # Save model\n",
    "    if e % 10 == 0:\n",
    "        agent.model.save_weights(\"./save_model/DQN_Agent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetBehaviorClient(1,\"robot_0\")\n",
    "goal_ = np.array([5,3,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetInfoClient(\"robot_1\",1)[\"my_health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ammo': 50,\n",
       " 'buff_left': {'nsecs': 0, 'secs': 0},\n",
       " 'buff_zone_cooltime': {'nsecs': 0, 'secs': 0},\n",
       " 'current_behavior_process': 2,\n",
       " 'current_behavior_style': 1,\n",
       " 'enemy_pose1': {'header': {'frame_id': '',\n",
       "   'seq': 0,\n",
       "   'stamp': {'nsecs': 0, 'secs': 0}},\n",
       "  'pose': {'orientation': {'w': 0.0, 'x': 0.0, 'y': 0.0, 'z': 0.0},\n",
       "   'position': {'x': 0.0, 'y': 0.0, 'z': 0.0}}},\n",
       " 'enemy_pose2': {'header': {'frame_id': '',\n",
       "   'seq': 0,\n",
       "   'stamp': {'nsecs': 0, 'secs': 0}},\n",
       "  'pose': {'orientation': {'w': 0.0, 'x': 0.0, 'y': 0.0, 'z': 0.0},\n",
       "   'position': {'x': 0.0, 'y': 0.0, 'z': 0.0}}},\n",
       " 'enemy_priority': 3,\n",
       " 'game_start_time': {'nsecs': 400000000, 'secs': 4},\n",
       " 'game_state': 2,\n",
       " 'goal': {'etc': 0.0,\n",
       "  'header': {'frame_id': 'robot_0/map',\n",
       "   'seq': 0,\n",
       "   'stamp': {'nsecs': 200000000, 'secs': 193}},\n",
       "  'x': 2.061732172649977,\n",
       "  'xa': 0.0,\n",
       "  'y': 0.9734800516102516,\n",
       "  'ya': 0.0,\n",
       "  'yaw': 0.0,\n",
       "  'yawa': 0.0},\n",
       " 'has_buff': False,\n",
       " 'how_many_enemies_detected': 0,\n",
       " 'is_enemy_1_detected': False,\n",
       " 'is_enemy_2_detected': False,\n",
       " 'is_hit': False,\n",
       " 'last_hit_time': {'nsecs': 0, 'secs': 0},\n",
       " 'locked_on_enemy': 0,\n",
       " 'my_health': 1000,\n",
       " 'my_pose': {'header': {'frame_id': 'robot_0/map',\n",
       "   'seq': 0,\n",
       "   'stamp': {'nsecs': 0, 'secs': 205}},\n",
       "  'pose': {'orientation': {'w': 0.9905062946940394,\n",
       "    'x': 0.0,\n",
       "    'y': 0.0,\n",
       "    'z': 0.1374673785720989},\n",
       "   'position': {'x': 2.01508103546965, 'y': 0.9571719811718515, 'z': 0.0}}},\n",
       " 'reload_zone_cooltime': {'nsecs': 0, 'secs': 0},\n",
       " 'stamp': {'nsecs': 0, 'secs': 205},\n",
       " 'time_passed_from_start': {'nsecs': 600000000, 'secs': 200},\n",
       " 'which_armor_hit': 102}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetInfoClient(\"robot_0\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset game\n",
    "# when referee says game is finished\n",
    "\n",
    "\n",
    "behav_=7\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([1,1,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "behav_=7\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([1,1,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=Green>시나리오</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_0 = GetInfoClient(\"robot_0\",1)\n",
    "info_1 = GetInfoClient(\"robot_1\",1)\n",
    "print \"robot_0 health: \" + str(info_0[\"my_health\"])\n",
    "print \"robot_1 health: \" + str(info_1[\"my_health\"])\n",
    "print \"robot_0 ammo: \" + str(info_0[\"ammo\"])\n",
    "print \"robot_1 ammo: \" + str(info_1[\"ammo\"])\n",
    "print \"robot_0 game_state: \" + str(info_0[\"game_state\"])\n",
    "print \"robot_1 game_state: \" + str(info_1[\"game_state\"])\n",
    "print \"robot_0 behavior: \" + str(info_0[\"current_behavior_style\"])\n",
    "print \"robot_1 behavior: \" + str(info_1[\"current_behavior_style\"])\n",
    "print \"robot_0 process: \" + str(info_0[\"current_behavior_process\"])\n",
    "print \"robot_1 process: \" + str(info_1[\"current_behavior_process\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCENARIO\n",
    "\n",
    "# blue and red meets at 5,3 and engage for 9 sec\n",
    "\n",
    "# red robot flanks\n",
    "# blue robot turns to the direction of the armor\n",
    "# engage again\n",
    "\n",
    "# red goes to reload and after 1 sec blue also reloads\n",
    "\n",
    "# after 10 sec, again meet at 1,1 and fight until one dies\n",
    "\n",
    "import time\n",
    "\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([5,3,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([3,2,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")\n",
    "\n",
    "time.sleep(9)\n",
    "\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([5,3,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")\n",
    "behav_=4\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([5,3,1,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "\n",
    "time.sleep(9)\n",
    "\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([5,3,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "\n",
    "time.sleep(0.8)\n",
    "\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([3,3,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "behav_=5\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([4,4.5,-1.5707,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "behav_=5\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([4,4.5,-1.5707,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_0\")\n",
    "goal_ = np.array([1,1,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_0\")\n",
    "behav_=1\n",
    "SetBehaviorClient(behav_,\"robot_1\")\n",
    "goal_ = np.array([7,4,0,0,0,0,0])\n",
    "SetGoalClient(goal_,\"robot_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
